#!/usr/bin/env python3
"""
Gemini Pro RAG Chatbot for Tin Hoc 11
Combines vector search with Google's Gemini Pro for intelligent Q&A
"""

import sys
import os
from pathlib import Path
import time
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from src.sgk_rag.core.vector_store import VectorStoreManager
    from src.sgk_rag.core.embedding_manager import EmbeddingManager
except ImportError:
    print("Warning: Could not import some modules. Using fallback.")

# Google Generative AI
import google.generativeai as genai

# Setup logging
import logging
logging.basicConfig(level=logging.WARNING)


class TinHoc11ChatBot:
    """RAG Chatbot using Gemini Pro and vector search"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Initialize the chatbot
        
        Args:
            api_key: Google API key for Gemini Pro (optional, can use env var)
        """
        print("ðŸ¤– Initializing Tin Hoc 11 AI Assistant...")
        
        # Initialize Gemini
        self._setup_gemini(api_key)
        
        # Initialize vector search
        self._setup_vector_search()
        
        # Conversation history
        self.conversation_history = []
        
        print("âœ… AI Assistant ready!")
    
    def _setup_gemini(self, api_key: Optional[str] = None):
        """Setup Gemini Pro"""
        try:
            # Get API key
            if api_key:
                genai.configure(api_key=api_key)
            elif os.getenv("GOOGLE_API_KEY"):
                genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
            else:
                # Prompt user for API key
                print("\nðŸ”‘ Google API Key required for Gemini Pro")
                print("Get your API key from: https://makersuite.google.com/app/apikey")
                api_key = input("Enter your Google API Key: ").strip()
                genai.configure(api_key=api_key)
                
                # Save to environment for this session
                os.environ["GOOGLE_API_KEY"] = api_key
            
            # Initialize the model
            self.model = genai.GenerativeModel('gemini-pro')
            
            # Test the connection
            response = self.model.generate_content("Hello")
            print("âœ… Gemini Pro connected successfully")
            
        except Exception as e:
            print(f"âŒ Failed to setup Gemini Pro: {e}")
            print("Please check your API key and try again")
            sys.exit(1)
    
    def _setup_vector_search(self):
        """Setup vector search system"""
        try:
            print("ðŸ”„ Loading textbook database...")
            
            self.embedding_manager = EmbeddingManager(
                model_name="multilingual",
                device="cpu"
            )
            
            self.vector_manager = VectorStoreManager(
                store_type="chroma",
                embedding_manager=self.embedding_manager,
                collection_name="sgk_tin_hoc_11_tin_hoc11"
            )
            
            self.vectorstore = self.vector_manager.load_vectorstore("sgk_tin_hoc_11_tin_hoc11")
            
            # Get database stats
            stats = self.vector_manager.get_statistics(self.vectorstore)
            print(f"âœ… Textbook loaded: {stats.get('total_documents', 'N/A')} documents")
            
        except Exception as e:
            print(f"âŒ Failed to setup vector search: {e}")
            sys.exit(1)
    
    def search_textbook(self, query: str, num_results: int = 3) -> List[Dict[str, Any]]:
        """Search the textbook for relevant content"""
        try:
            results = self.vector_manager.search(
                vectorstore=self.vectorstore,
                query=query,
                k=num_results
            )
            
            processed_results = []
            for result in results:
                processed_results.append({
                    'content': result.page_content,
                    'page': result.metadata.get('page_number', 'N/A'),
                    'source': 'Tin há»c 11'
                })
            
            return processed_results
            
        except Exception as e:
            print(f"âŒ Search failed: {e}")
            return []
    
    def generate_answer(self, question: str, context_results: List[Dict]) -> str:
        """Generate answer using Gemini Pro with textbook context"""
        
        # Build context from search results
        context = ""
        for i, result in enumerate(context_results, 1):
            context += f"\n[Trang {result['page']}]\n{result['content']}\n"
        
        # Create the prompt in Vietnamese
        prompt = f"""Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn vá» Tin há»c, Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ giÃºp há»c sinh há»c mÃ´n Tin há»c lá»›p 11.

NGUYÃŠN Táº®C TRáº¢ Lá»œI:
1. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, rÃµ rÃ ng vÃ  dá»… hiá»ƒu
2. Sá»­ dá»¥ng thÃ´ng tin tá»« sÃ¡ch giÃ¡o khoa Ä‘Æ°á»£c cung cáº¥p
3. Giáº£i thÃ­ch khÃ¡i niá»‡m má»™t cÃ¡ch Ä‘Æ¡n giáº£n, phÃ¹ há»£p vá»›i há»c sinh
4. ÄÆ°a ra vÃ­ dá»¥ cá»¥ thá»ƒ khi cÃ³ thá»ƒ
5. Náº¿u khÃ´ng cÃ³ thÃ´ng tin trong sÃ¡ch, hÃ£y nÃ³i rÃµ vÃ  Ä‘Æ°a ra kiáº¿n thá»©c tá»•ng quÃ¡t

THÃ”NG TIN Tá»ª SÃCH GIÃO KHOA:
{context}

CÃ‚U Há»ŽI Cá»¦A Há»ŒC SINH:
{question}

HÃƒY TRáº¢ Lá»œI CÃ‚U Há»ŽI Dá»°A TRÃŠN THÃ”NG TIN SÃCH GIÃO KHOA VÃ€ KIáº¾N THá»¨C TIN Há»ŒC:"""

        try:
            response = self.model.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"âŒ Lá»—i khi táº¡o cÃ¢u tráº£ lá»i: {e}"
    
    def chat(self, user_input: str) -> Dict[str, Any]:
        """Process a chat message and return response"""
        
        # Search for relevant content
        print("ðŸ” Äang tÃ¬m kiáº¿m thÃ´ng tin...")
        search_results = self.search_textbook(user_input, num_results=3)
        
        if not search_results:
            # No search results, use general knowledge
            prompt = f"""Báº¡n lÃ  trá»£ lÃ½ AI vá» Tin há»c. CÃ¢u há»i: {user_input}
            
HÃ£y tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, Ä‘Æ¡n giáº£n vÃ  phÃ¹ há»£p vá»›i há»c sinh lá»›p 11."""
            
            try:
                response = self.model.generate_content(prompt)
                answer = response.text
            except Exception as e:
                answer = f"âŒ Lá»—i: {e}"
            
            return {
                'question': user_input,
                'answer': answer,
                'sources': [],
                'search_results': []
            }
        
        # Generate answer with context
        print("ðŸ¤– Äang táº¡o cÃ¢u tráº£ lá»i...")
        answer = self.generate_answer(user_input, search_results)
        
        # Add to conversation history
        self.conversation_history.append({
            'question': user_input,
            'answer': answer,
            'timestamp': time.time()
        })
        
        return {
            'question': user_input,
            'answer': answer,
            'sources': [f"Trang {r['page']}" for r in search_results],
            'search_results': search_results
        }
    
    def get_conversation_history(self) -> List[Dict]:
        """Get conversation history"""
        return self.conversation_history
    
    def clear_history(self):
        """Clear conversation history"""
        self.conversation_history = []
        print("ðŸ—‘ï¸ ÄÃ£ xÃ³a lá»‹ch sá»­ trÃ² chuyá»‡n")


def interactive_chat():
    """Interactive chat interface"""
    print("ðŸ‡»ðŸ‡³ TIN Há»ŒC 11 AI ASSISTANT")
    print("=" * 60)
    print("Trá»£ lÃ½ AI chuyÃªn vá» Tin há»c lá»›p 11")
    print("Powered by Google Gemini Pro + Vector Search")
    print("=" * 60)
    print()
    print("ðŸ“– TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:")
    print("  â€¢ Tráº£ lá»i cÃ¢u há»i vá» Tin há»c")
    print("  â€¢ Giáº£i thÃ­ch khÃ¡i niá»‡m, Ä‘á»‹nh nghÄ©a")
    print("  â€¢ HÆ°á»›ng dáº«n sá»­ dá»¥ng pháº§n má»m")
    print("  â€¢ TÃ¬m thÃ´ng tin trong sÃ¡ch giÃ¡o khoa")
    print()
    print("ðŸ’¡ Lá»‡nh Ä‘áº·c biá»‡t:")
    print("  â€¢ 'examples' - Xem cÃ¢u há»i máº«u")
    print("  â€¢ 'history' - Xem lá»‹ch sá»­ trÃ² chuyá»‡n")
    print("  â€¢ 'clear' - XÃ³a lá»‹ch sá»­")
    print("  â€¢ 'quit' - ThoÃ¡t")
    print("=" * 60)
    
    # Initialize chatbot
    chatbot = TinHoc11ChatBot()
    
    # Example questions
    example_questions = [
        "Há»‡ Ä‘iá»u hÃ nh lÃ  gÃ¬?",
        "Pháº§n má»m á»©ng dá»¥ng khÃ¡c gÃ¬ vá»›i pháº§n má»m há»‡ thá»‘ng?",
        "CÃ¡ch báº£o vá»‡ mÃ¡y tÃ­nh khá»i virus?",
        "Windows cÃ³ nhá»¯ng tÃ­nh nÄƒng gÃ¬?",
        "LÃ m tháº¿ nÃ o Ä‘á»ƒ táº¡o folder má»›i?",
        "Internet hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?",
        "CÃ¡ch sao lÆ°u dá»¯ liá»‡u an toÃ n?",
        "Microsoft Office gá»“m nhá»¯ng á»©ng dá»¥ng nÃ o?"
    ]
    
    try:
        while True:
            print("\n" + "="*80)
            user_input = input("ðŸ™‹ HÃ£y Ä‘áº·t cÃ¢u há»i: ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() in ['quit', 'exit', 'thoÃ¡t', 'q']:
                print("ðŸ‘‹ Táº¡m biá»‡t! ChÃºc báº¡n há»c tá»‘t!")
                break
            
            if user_input.lower() in ['examples', 'vÃ­ dá»¥', 'máº«u']:
                print("\nðŸ’¡ CÃ‚U Há»ŽI MáºªU:")
                for i, example in enumerate(example_questions, 1):
                    print(f"  {i}. {example}")
                print("\nðŸ“ HÃ£y copy má»™t cÃ¢u há»i hoáº·c Ä‘áº·t cÃ¢u há»i cá»§a riÃªng báº¡n!")
                continue
            
            if user_input.lower() in ['history', 'lá»‹ch sá»­']:
                history = chatbot.get_conversation_history()
                if history:
                    print("\nðŸ“š Lá»ŠCH Sá»¬ TRÃ’ CHUYá»†N:")
                    for i, item in enumerate(history[-5:], 1):  # Show last 5
                        print(f"\n{i}. Q: {item['question']}")
                        print(f"   A: {item['answer'][:100]}...")
                else:
                    print("ðŸ“ ChÆ°a cÃ³ lá»‹ch sá»­ trÃ² chuyá»‡n")
                continue
            
            if user_input.lower() in ['clear', 'xÃ³a']:
                chatbot.clear_history()
                continue
            
            # Process the question
            print("\n" + "="*80)
            print(f"ðŸ™‹ CÃ¢u há»i: {user_input}")
            print("-" * 80)
            
            response = chatbot.chat(user_input)
            
            # Display answer
            print("ðŸ¤– Tráº£ lá»i:")
            print(response['answer'])
            
            # Display sources if available
            if response['sources']:
                print(f"\nðŸ“š Nguá»“n tham kháº£o: {', '.join(response['sources'])}")
            
            # Ask if user wants to see search results
            if response['search_results']:
                show_sources = input("\nðŸ“– Xem thÃ´ng tin chi tiáº¿t tá»« sÃ¡ch? (y/n): ").strip().lower()
                if show_sources in ['y', 'yes', 'cÃ³', 'c']:
                    print("\nðŸ“š THÃ”NG TIN Tá»ª SÃCH GIÃO KHOA:")
                    for i, result in enumerate(response['search_results'], 1):
                        print(f"\nðŸ“„ {i}. Trang {result['page']}:")
                        print("-" * 40)
                        content = result['content']
                        if len(content) > 300:
                            content = content[:300] + "..."
                        print(content)
    
    except KeyboardInterrupt:
        print("\n\nðŸ‘‹ Táº¡m biá»‡t! ChÃºc báº¡n há»c tá»‘t!")
    except Exception as e:
        print(f"\nâŒ Lá»—i: {e}")


def quick_test():
    """Quick test of the chatbot"""
    print("ðŸ§ª TESTING GEMINI PRO CHATBOT")
    print("=" * 40)
    
    chatbot = TinHoc11ChatBot()
    
    test_questions = [
        "Há»‡ Ä‘iá»u hÃ nh lÃ  gÃ¬?",
        "Pháº§n má»m á»©ng dá»¥ng cÃ³ nhá»¯ng loáº¡i nÃ o?",
        "CÃ¡ch báº£o vá»‡ mÃ¡y tÃ­nh?"
    ]
    
    for i, question in enumerate(test_questions, 1):
        print(f"\nðŸ” Test {i}: {question}")
        print("-" * 40)
        
        response = chatbot.chat(question)
        
        print("ðŸ¤– Answer:")
        print(response['answer'][:200] + "..." if len(response['answer']) > 200 else response['answer'])
        
        if response['sources']:
            print(f"ðŸ“š Sources: {', '.join(response['sources'])}")
    
    print("\nâœ… Test completed!")


def main():
    """Main function"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Tin Hoc 11 AI Chatbot")
    parser.add_argument('--test', action='store_true', help='Run quick test')
    parser.add_argument('--api-key', type=str, help='Google API key')
    
    args = parser.parse_args()
    
    if args.test:
        quick_test()
    else:
        interactive_chat()


if __name__ == "__main__":
    main()