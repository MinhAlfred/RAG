"""FastAPI Server - API cho RAG Q&A v√† Slide Generation"""

import time
import json
import traceback
from datetime import datetime
from typing import List, Dict, Any
from pathlib import Path

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

from ..core.rag_pipeline import RAGPipeline
from ..models.dto import (
    QuestionRequest, QuestionResponse, SlideRequest, SlideResponse,
    HealthResponse, ErrorResponse, BatchQuestionRequest, BatchQuestionResponse,
    SourceInfo, SlideContent, QuestionType, SlideFormat,
    JsonSlideResponse  # Import JSON response model
)
from .slide_generator import SlideGenerator


# Kh·ªüi t·∫°o FastAPI app
app = FastAPI(
    title="SGK Informatics RAG API",
    description="API cho h·ªá th·ªëng RAG Q&A v√† t·∫°o slide t·ª´ SGK Tin h·ªçc",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Trong production n√™n gi·ªõi h·∫°n origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global variables
rag_pipeline: RAGPipeline = None
slide_generator: SlideGenerator = None


@app.on_event("startup")
async def startup_event():
    """Kh·ªüi t·∫°o RAG pipeline khi start server"""
    global rag_pipeline, slide_generator
    
    try:
        print("üöÄ ƒêang kh·ªüi t·∫°o RAG Pipeline...")
        
        # Kh·ªüi t·∫°o RAG pipeline v·ªõi Ollama llama3.2:3b
        # S·ª≠ d·ª•ng collection sgk_tin (t·∫•t c·∫£ l·ªõp 3-12)
        rag_pipeline = RAGPipeline(
            vector_store_path="data/vectorstores",
            llm_type="ollama",
            model_name="llama3.2:3b",
            collection_name="sgk_tin"
        )
        
        # Kh·ªüi t·∫°o slide generator
        slide_generator = SlideGenerator(rag_pipeline)
        
        print("‚úÖ RAG Pipeline ƒë√£ s·∫µn s√†ng!")
        
        # Test pipeline
        test_response = rag_pipeline.query("M√°y t√≠nh l√† g√¨?")
        if isinstance(test_response, str):
            print(f"üß™ Test query th√†nh c√¥ng: {test_response[:100]}...")
        else:
            print(f"üß™ Test query th√†nh c√¥ng: {str(test_response)[:100]}...")
        
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o RAG Pipeline: {e}")
        print(traceback.format_exc())
        raise


@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """Global exception handler"""
    return JSONResponse(
        status_code=500,
        content=ErrorResponse(
            error="Internal Server Error",
            detail=str(exc),
            status_code=500,
            timestamp=datetime.now().isoformat()
        ).dict()
    )


@app.get("/", response_model=Dict[str, str])
async def root():
    """Root endpoint"""
    return {
        "message": "SGK Informatics RAG API",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health"
    }


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint"""
    try:
        # Ki·ªÉm tra RAG pipeline
        if rag_pipeline is None:
            raise HTTPException(status_code=503, detail="RAG Pipeline ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o")
        
        # L·∫•y th√¥ng tin vector store
        vector_store_info = {}
        try:
            stats = rag_pipeline.get_stats()
            vector_store_info = {
                "total_chunks": stats.get("total_chunks", 0),
                "embedding_dim": stats.get("embedding_dim", 0),
                "index_type": stats.get("index_type", "unknown")
            }
        except:
            vector_store_info = {"status": "unavailable"}
        
        # Th√¥ng tin model
        model_info = {
            "llm_type": "ollama",
            "model_name": "llama3.2:3b",
            "embedding_model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        }
        
        return HealthResponse(
            status="healthy",
            version="1.0.0",
            rag_status="ready",
            vector_store_info=vector_store_info,
            model_info=model_info
        )
        
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Health check failed: {str(e)}")


@app.post("/ask", response_model=QuestionResponse)
async def ask_question(request: QuestionRequest):
    """Endpoint ƒë·ªÉ h·ªèi c√¢u h·ªèi"""
    start_time = time.time()
    
    try:
        if rag_pipeline is None:
            raise HTTPException(status_code=503, detail="RAG Pipeline ch∆∞a s·∫µn s√†ng")
        
        # Query RAG pipeline v·ªõi return_sources
        response = rag_pipeline.query(
            request.question,
            grade_filter=request.grade_filter,
            return_sources=request.return_sources
        )
        
        # Extract answer v√† sources t·ª´ response
        if isinstance(response, dict):
            answer = response.get('answer', str(response))
            # Sources ƒë√£ ƒë∆∞·ª£c tr·∫£ v·ªÅ t·ª´ query() n·∫øu return_sources=True
            sources_data = response.get('sources', [])
            
            # Convert sources sang SourceInfo format
            sources = []
            if request.return_sources and sources_data:
                for src in sources_data:
                    metadata = src.get('metadata', {})
                    # Convert grade to string (metadata c√≥ th·ªÉ ch·ª©a int ho·∫∑c str)
                    grade_value = metadata.get("grade", "Kh√¥ng x√°c ƒë·ªãnh")
                    grade_str = str(grade_value) if grade_value is not None else "Kh√¥ng x√°c ƒë·ªãnh"
                    
                    sources.append(
                        SourceInfo(
                            content=src.get('content', ''),
                            grade=grade_str,
                            lesson_title=metadata.get("lesson_title", "Kh√¥ng x√°c ƒë·ªãnh") or "Kh√¥ng x√°c ƒë·ªãnh",
                            score=float(metadata.get('score', 0.0)),
                            chunk_id=metadata.get("chunk_id")
                        )
                    )
        else:
            answer = str(response)
            sources = []
        
        processing_time = time.time() - start_time
        
        return QuestionResponse(
            question=request.question,
            answer=answer,
            status="success",
            sources=sources if request.return_sources else None,
            processing_time=processing_time
        )
        
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"L·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {e}")
        
        return QuestionResponse(
            question=request.question,
            answer="",
            status="error",
            sources=None,
            processing_time=processing_time,
            error=str(e)
        )


@app.post("/ask/batch", response_model=BatchQuestionResponse)
async def ask_batch_questions(request: BatchQuestionRequest):
    """Endpoint ƒë·ªÉ h·ªèi nhi·ªÅu c√¢u h·ªèi c√πng l√∫c"""
    start_time = time.time()
    
    try:
        if rag_pipeline is None:
            raise HTTPException(status_code=503, detail="RAG Pipeline ch∆∞a s·∫µn s√†ng")
        
        results = []
        successful = 0
        failed = 0
        
        for question in request.questions:
            try:
                # T·∫°o QuestionRequest cho t·ª´ng c√¢u h·ªèi
                q_request = QuestionRequest(
                    question=question,
                    question_type=request.question_type,
                    grade_filter=request.grade_filter,
                    return_sources=request.return_sources,
                    max_sources=3  # Gi·ªõi h·∫°n sources cho batch
                )
                
                # G·ªçi ask_question
                response = await ask_question(q_request)
                results.append(response)
                
                if response.status == "success":
                    successful += 1
                else:
                    failed += 1
                    
            except Exception as e:
                failed += 1
                results.append(QuestionResponse(
                    question=question,
                    answer="",
                    status="error",
                    error=str(e),
                    processing_time=0
                ))
        
        total_time = time.time() - start_time
        
        return BatchQuestionResponse(
            results=results,
            total_questions=len(request.questions),
            successful=successful,
            failed=failed,
            processing_time=total_time
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Batch processing failed: {str(e)}")


@app.post("/slides/generate", response_model=SlideResponse)
async def generate_slides(request: SlideRequest):
    """Endpoint ƒë·ªÉ t·∫°o slides (legacy - tr·∫£ v·ªÅ SlideResponse)"""
    start_time = time.time()
    
    try:
        if slide_generator is None:
            raise HTTPException(status_code=503, detail="Slide Generator ch∆∞a s·∫µn s√†ng")
        
        # N·∫øu format l√† JSON, redirect t·ªõi JSON endpoint
        if request.format == SlideFormat.JSON:
            return JSONResponse(
                content={
                    "error": "Use /slides/generate/json endpoint for JSON format",
                    "redirect": "/slides/generate/json"
                },
                status_code=400
            )
        
        # T·∫°o slides
        slides = slide_generator.generate_slides(request)
        
        # Format slides theo y√™u c·∫ßu
        formatted_content = slide_generator.format_slides(slides, request.format)
        
        # C·∫≠p nh·∫≠t content c·ªßa slides v·ªõi formatted content n·∫øu c·∫ßn
        if request.format != SlideFormat.MARKDOWN:
            # T·∫°o m·ªôt slide t·ªïng h·ª£p cho c√°c format kh√°c
            summary_slide = SlideContent(
                slide_number=0,
                title=f"Slides - {request.topic}",
                content=formatted_content,
                notes=f"Slides ƒë∆∞·ª£c format theo {request.format.value}",
                sources=[]
            )
            slides = [summary_slide]
        
        processing_time = time.time() - start_time
        
        return SlideResponse(
            topic=request.topic,
            slides=slides,
            format=request.format,
            total_slides=len(slides),
            grade_level=f"L·ªõp {request.grade}" if request.grade else None,
            status="success",
            processing_time=processing_time
        )
        
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"L·ªói khi t·∫°o slides: {e}")
        print(traceback.format_exc())
        
        return SlideResponse(
            topic=request.topic,
            slides=[],
            format=request.format,
            total_slides=0,
            grade_level=f"L·ªõp {request.grade}" if request.grade else None,
            status="error",
            processing_time=processing_time,
            error=str(e)
        )


@app.post("/slides/generate/json", response_model=JsonSlideResponse)
async def generate_slides_json(request: SlideRequest):
    """
    Endpoint ƒë·ªÉ t·∫°o slides v·ªõi JSON structure - d√†nh cho Spring Boot integration
    
    Tr·∫£ v·ªÅ structured JSON v·ªõi:
    - Typed slides (title, content, code, image, exercise)
    - Flexible content (string, list, dict)
    - Metadata (duration, sources, timestamp)
    - Type-safe v·ªõi Pydantic models
    """
    try:
        if slide_generator is None:
            raise HTTPException(status_code=503, detail="Slide Generator ch∆∞a s·∫µn s√†ng")
        
        # T·∫°o slides v·ªõi JSON structure
        json_response = slide_generator.generate_slides_json(request)
        
        return json_response
        
    except Exception as e:
        print(f"L·ªói khi t·∫°o JSON slides: {e}")
        print(traceback.format_exc())
        
        raise HTTPException(
            status_code=500,
            detail=f"Failed to generate JSON slides: {str(e)}"
        )


@app.get("/slides/formats")
async def get_slide_formats():
    """L·∫•y danh s√°ch c√°c format slide h·ªó tr·ª£"""
    return {
        "formats": [
            {"value": "markdown", "label": "Markdown", "description": "Format Markdown chu·∫©n"},
            {"value": "html", "label": "HTML", "description": "HTML v·ªõi CSS styling"},
            {"value": "powerpoint", "label": "PowerPoint Guide", "description": "H∆∞·ªõng d·∫´n t·∫°o PowerPoint"},
            {"value": "text", "label": "Plain Text", "description": "Text thu·∫ßn kh√¥ng format"},
            {
                "value": "json",
                "label": "JSON Structure",
                "description": "Structured JSON cho Spring Boot integration (use /slides/generate/json endpoint)"
            }
        ]
    }


@app.get("/question/types")
async def get_question_types():
    """L·∫•y danh s√°ch c√°c lo·∫°i c√¢u h·ªèi h·ªó tr·ª£"""
    return {
        "types": [
            {"value": "general", "label": "C√¢u h·ªèi chung", "description": "C√¢u h·ªèi th√¥ng th∆∞·ªùng"},
            {"value": "slide", "label": "T·∫°o slide", "description": "Y√™u c·∫ßu t·∫°o n·ªôi dung slide"},
            {"value": "explain", "label": "Gi·∫£i th√≠ch", "description": "Gi·∫£i th√≠ch kh√°i ni·ªám"},
            {"value": "example", "label": "V√≠ d·ª•", "description": "Y√™u c·∫ßu v√≠ d·ª• c·ª• th·ªÉ"}
        ]
    }


@app.get("/stats")
async def get_system_stats():
    """L·∫•y th·ªëng k√™ h·ªá th·ªëng"""
    try:
        if rag_pipeline is None:
            raise HTTPException(status_code=503, detail="RAG Pipeline ch∆∞a s·∫µn s√†ng")
        
        stats = rag_pipeline.get_stats()
        
        return {
            "rag_pipeline": stats,
            "api_info": {
                "version": "1.0.0",
                "endpoints": [
                    "/ask", "/ask/batch", "/slides/generate", 
                    "/health", "/stats", "/question/types", "/slides/formats"
                ],
                "models": {
                    "llm": "ollama/llama3.2:3b",
                    "embedding": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
                }
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get stats: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    
    print("üöÄ Starting SGK Informatics RAG API...")
    print("üìö S·ª≠ d·ª•ng Ollama llama3.2:3b")
    print("üîó API docs: http://localhost:8000/docs")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )